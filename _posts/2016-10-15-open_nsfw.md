---
layout: post
title: open_nsfw 试用
---

## 简介
NSFW 是 Not Suitable for Work 的缩写(不适合工作场合)

open_nsfw 是 yahoo 开源的一个用来检测色情图片(NSFW)的软件项目: https://github.com/yahoo/open_nsfw

## 试用
### 下载 open_nsfw
```
git clone https://github.com/yahoo/open_nsfw
```

### 安装依赖 这里选择README中推荐的 Docker 方案
```
docker build -t caffe:cpu https://raw.githubusercontent.com/BVLC/caffe/master/docker/standalone/cpu/Dockerfile

or:
  wget https://raw.githubusercontent.com/BVLC/caffe/master/docker/standalone/cpu/Dockerfile
  #edit Dockerfile
  #sed -i 's;archive.ubuntu.com;cn.&;' /etc/apt/sources.list;
  #add option -i http://pypi.douban.com/simple for  pip install
  #sudo docker build -t caffe:cpu .
```

### 实测
```
cd open_nsfw
mkdir images
cp ~/Picture/test/*.jpg  images/.

su -c "setenforce 0" # chcon -Rt svirt_sandbox_file_t /path/to/volume
for t in images/*; do
    val=$(sudo docker run --volume=$(pwd):/workspace caffe:cpu python ./classify_nsfw.py --model_def nsfw_model/deploy.prototxt --pretrained_model nsfw_model/resnet_50_1by2_nsfw.caffemodel $t 2>/dev/null | awk 'BEGIN{OFS="-"} {printf("%1.12f", $3)}');
    echo $val $t;
    #mv $t ${t/\///NSFW-$val-}
done
```

## 感受
效果还行，但也有不少误判:

很正常的图片，只是因为衣服颜色跟肤色特别接近，从而得到很高的分数(分数越高，越可能 NSFW)

暴露但是因为着深色服饰(黑丝or...)，从而得道很低的分值；(但也有个别的深色服饰也能给出相称的分值...)

=>
Update:

找到另外一个更专业 open_nsfw 的测试:
  https://github.com/tjwei/play_nsfw
  
里面提到了 Inverse open NSFW，很容易反转/修改图片的在 open_nsfw 的分值，看来相关技术还有很大进步空间。。
